---
title: "Building intuition into popgen concepts and simulation-based inference"
subtitle: "Exercises for the [Workshop on population and speciation genomics](http://evomics.org/workshops/workshop-on-population-and-speciation-genomics/2025-workshop-on-population-and-speciation-genomics-cesky-krumlov/)"
author:
  - "Martin Petr"
  - "[CC BY 4.0](https://creativecommons.org/licenses/by/4.0/)"
date: "January 2025"
date-format: "MMMM YYYY"
format:
  html:
    toc: true
    echo: true
    code-line-numbers: false
    fig-align: center
    self-contained: true
    callout-appearance: minimal
filters: 
 - collapse-callout.lua
---

<!-- TODO: Looks at these links to define a custom "Show the solution" callout -->

<!-- https://www.youtube.com/watch?v=DDQO_3R-q74 -->

<!-- https://examples.quarto.pub/collapse-callout/ -->






























# Reference materials

Unless you're already an expert on the *slendr* toolkit, you will probably need some reference materials to do the exercises. Here are the options:

1.  You can refer to the slides with the *slendr* crash course. You can find the material rendered as [normal slides](https://bodkan.quarto.pub/cesky-krumlov-2025-slides/) or [one-page handouts](https://bodkan.quarto.pub/cesky-krumlov-2025-handouts/) (the latter being probably a bit more practical for reference.
2.  Relevant tutorials on the [*slendr* website](https://www.slendr.net) which you can find under the "Articles" link in the header.
3.  [Manual pages](https://www.slendr.net/reference/index.html) of all available *slendr* functions. Note that you can get the help page of every *slendr* R `function` by typing `?function` in the R console. For instance, typing `?ts_tajima` gives you the help page of the *tskit*/*slendr* function implementing the tree-based computation of Tajima's D.































# Installation setup

The easiest way to set up everything on your computer is to do the following:

1.  Clone the repository with the activity materials (source code with slides and exercises materials, example scripts, and solutions). In a shell terminal on Linux or macOS, in your home directory (or anywhere else, really) you can run:

    ```         
    $ git clone https://github.com/bodkan/cesky-krumlov-2025 ~/slendr_activity
    ```

2.  Install all the R package dependencies by going into the activity repository directory you just cloned and installing the necessary R packages by following these steps:

-   First go into the project directory you just cloned:

    ```         
    $ cd ~/slendr_activity
    ```

-   Open the R terminal in that directory. You should get a note that the *renv* package is being automatically setup, like this:

    ```         
    $ R

    [... R startup information stuff ...]

    # Bootstrapping renv 1.0.11 --------------------------------------------------
    - Downloading renv ... OK
    - Installing renv  ... OK

    - Project '~/slendr_activity' loaded. [renv 1.0.11]
    - One or more packages recorded in the lockfile are not installed.
    - Use `renv::status()` for more details.
    ```

-   Install the R package dependencies (still in the R console!):

    ```         
    > renv::restore(prompt = FALSE)
    ```

-   Set up the Python environment used by the *slendr* R package for simulation and tree-sequence analysis (still in the R console!):

    ```         
    > slendr::setup_env(agree = TRUE)
    ```

    If everything worked, you should get an optimistic message saying:

    ```         
    ======================================================================
    Python environment for slendr has been successfuly created, and the R
    interface to msprime, tskit, and pyslim modules has been activated.

    In future sessions, activate this environment by calling init_env().
    =======================================================================
    ```

4.  Open RStudio and navigate to your project directory via `File -> Open Project...`.

**If the `setup_env()` installation procedure fails, try the following:**

1.  Delete the failed installation attempt:

```         
slendr::clear_env(force = TRUE, all = TRUE)
```

2.  Try installing it again, this time using `pip` as a Python installation method (the default is `conda` which unfortunately fails fairly often):

```         
slendr::setup_env(agree = TRUE, pip = TRUE)
```

In every previous installments of this workshop, this is all that was needed to resolve problems.

**Installing SLiM**

It's unclear whether we will manage to go through the entirety of the final exercise. However, to be able to do this, having SLiM at least version 4.2 (and it being available in your unix `$PATH!`) is required. If this isn't possible for your, don't worry. You'll be able to do most of that exercise even without SLiM, and I will demonstrate the whole exercise (including the SLiM bit) for you.































# Organization of the exercises

For each exercise, you will get a brief explanation of the problem at hand and functions that could be useful to solve the exercise. **The concrete, specific task will be always written like this in bold.**

Your goal for each exercise is to write a complete R script script. I suggest you name the script for each exercise as `exercise1.R`, `exercise2.R`, etc., just to keep things tidy.

Unless you have a strong preference for another editor or IDE, I recommend you use RStudio (either on your machine or in the cloud, as provided by the workshop organizers, depending on where you did the setup steps above).

Each exercise is compose of individual *parts*, which are designed to build one upon the other in the order they are specified.

#### Note on the programming aspect of the exercises

All the exercises will involve "real coding"! If you've never really programmed entire scripts before, this could feel a little intimidating. Don't worry. If you're ever lost, just take a peek at the solution which is (by default hidden) under each exercise section. Always try to work on a solution on your own, but never let this be a barrier to your progress. Feel free to copy-paste bits of my solutions into your own scripts.

If you find yourself [*totally lost*](https://scryfall.com/card/gtc/54/totally-lost), don't hesitate to read my solutions from the get go, copy-pasting them into your own script in the RStudio, executing them line by line, and trying to understand what's going on.































# Exercise 1: Programming demographic models with *slendr*

### Part 1: Building a demographic model in *slendr*

Use functions such as `population()`, `gene_flow()`, and `compile_model()` to **program the following toy model of human demographic history in *slendr*.**

![](images/intro_model1.png){width="50%"}

**Hint:** Start script `exercise1.R` script in your RStudio session using this "template":

```{r}
#| eval: false
#| code-fold: false
library(slendr)
init_env()

<... population definitions ...>
<... gene-flow definition ...>

model <- compile_model(
  populations = list(...),
  gene_flow = <...>,
  generation_time = 30
)
```

::: aside
**Note:** With *slendr* you can specify time in whatever format is more convenient or readable for your model. For instance here, because we're dealing with historical events which are commonly expressed in times given as"years ago", we can write them in a decreasing order – i.e. 7Mya → 6Mya → ..., as shown above – or, in terms of R code, 7e6 (or 7000000), 6e6 (6000000), etc..
:::

::: callout-note
#### Click to see the solution

```{r}
#| collapse: true
library(slendr)
init_env()

# Chimpanzee outgroup
chimp <- population("CHIMP", time = 7e6, N = 5000)

# Two populations of anatomically modern humans: Africans and Europeans
afr <- population("AFR", parent = chimp, time = 6e6, N = 15000)
eur <- population("EUR", parent = afr, time = 70e3, N = 3000)

# Neanderthal population splitting at 600 ky ago from modern humans
# (becomes extinct by 40 ky ago)
nea <- population("NEA", parent = afr, time = 600e3, N = 1000, remove = 40e3)

# Neanderthal introgression event (3% admixture between 55-50 kya)
gf <- gene_flow(from = nea, to = eur, rate = 0.03, start = 55000, end = 50000)

# Compile the entire model into a single slendr R object
model <- compile_model(
  populations = list(chimp, nea, afr, eur),
  gene_flow = gf,
  generation_time = 30,
  path = here::here("data/introgression"),  # <--- don't worry about these two
  overwrite = TRUE, force = TRUE            #      lines of code (ask me if interested)
)
```
:::

### Part 2: Inspecting the model visually

To visualize a *slendr* model, you can use the function `plot_model()`. **Plot your compiled `model` to make sure you programmed it correctly!**

::: aside
**Note:** Plotting of models can be sometimes a little wonky. When plotting your model, experiment with arguments `log = TRUE`, `proportions = TRUE`, `gene_flow = TRUE`. Check `?plot_model` for more information on these.
:::

::: callout-note
#### Click to see the solution

```{r}
#| collapse: false
plot_model(model)
plot_model(model, sizes = FALSE)
plot_model(model, sizes = FALSE, log = TRUE)
plot_model(model, sizes = FALSE, log = TRUE, proportions = TRUE)
```
:::

### Part 3: Simulating genomic data

Once you have a compiled *slendr* model stored in an R variable (from now on, `model` will always mean a variable containing a compiled *slendr* model object, for simplicity), we can simulate data from it. By default, *slendr* models always produce a [tree sequence](https://tskit.dev/tutorials/what_is.html).

There are two simulation engines built into *slendr* implemented by functions `msprime()` and `slim()`. For traditional, non-spatial, neutral demographic models, the engine provided by the `msprime()` function is much more efficient, so we'll be using that.

Here's how you can use it to simulate a tree sequence:

```{r}
#| eval: false
#| code-fold: false
ts <- msprime(<model object>, sequence_length = <length of sequence to simulate [as bp]>, recombination_rate = <uniform recombination rate [per bp per generation]>)
```

The function has also arguments `debug` and `run`.

**Simulate a tree sequence from your compiled `model`, storing it to a variable `ts` as shown right above. Then experiment with setting `debug = TRUE` (this prints out *msprime*'s own debugging summary) and then `run = FALSE` (this prints out a raw command-line which can run a *slendr* simulation in the shell).**

::: callout-note
#### Click to see the solution

```{r}
#| collapse: true
# This simulates a tskit tree sequence from a slendr model. Note that you didn't have
# to write any msprime or tskit Python code!
ts <- msprime(model, sequence_length = 1e6, recombination_rate = 1e-8)

# Setting `debug = TRUE` instructs slendr's built-in msprime script to print
# out msprime's own debugger information. This can be very useful for debugging,
# in addition to the visualization of the model as shown above.
ts <- msprime(model, sequence_length = 1e6, recombination_rate = 1e-8, debug = TRUE)

# For debugging of technical issues (with msprime, with slendr, or both), it is
# very useful to have the `msprime` function dump the "raw" command-line to
# run the simulation on the terminal using plain Python interpreter
msprime(model, sequence_length = 1e6, recombination_rate = 1e-8, run = FALSE)
```
:::

### Part 4: Inspecting the tree-sequence object

As we'll see later, *slendr* tries to provide an R-friendly interface to accessing a subset of *tskit*'s functionality for working with tree sequence and for computing various popgen statistics.

For now, **type out the `ts` object in the terminal – what do you see?** You should get a summary of a tree-sequence object that you're familiar with from your *msprime* and *tskit* activity.

::: callout-note
#### Click to see the solution

```{r}
# Typing out the object with the result shows that it's a good old tskit
# tree-sequence object
ts
```
:::

**Use the `ts_table` function to inspect the low-level table-based representation of a tree sequence.** For instance, you can get the table of nodes with `ts_table(ts, "nodes")`, edges with `ts_table(ts, "edges")`, and do the same thing for "individuals", "mutations", and "sites". Does your tree sequence contain any mutations? If not, why?

::: callout-note
#### Click to see the solution

```{r}
# slendr provides a helper function which allows access to all the low-level
# components of every tree-sequence object
ts_table(ts, "nodes")
ts_table(ts, "edges")
ts_table(ts, "individuals")
# We didn't simulate any mutations, so we only have genealogies for now.
ts_table(ts, "mutations")
ts_table(ts, "sites")
```
:::

There are also two *slendr*-specific functions called `ts_samples()` and `ts_nodes()`. **You can run them simply as `ts_samples(ts)` and `ts_nodes(ts)`. What do the tables they produce represent?**

::: callout-note
#### Click to see the solution

```{r}
# slendr provides a convenient function `ts_samples()` which allows us to
# inspect the contents of a simulated tree sequence in a more human-readable,
# simplified way. We can see that our tree sequence contains a massive number
# of individuals. Too many, in fact (we recorded every single individual alive
# at the end of our simulation -- something we're unlikely to be ever lucky
# enough to have, regardless of which species we study)
ts_samples(ts) %>% nrow()

# This function returns a table similar to the one produced by `ts_table(ts, "nodes")`
# above, except that it contains additional slendr metadata (names of individuals
# belonging to each node, spatial coordinates of nodes for spatial models, etc.).
# It's a bit more useful for analyzing tree-sequence data than the "low-level" functions.
ts_nodes(ts)
```
:::

### Part 5: Scheduling sampling events

In the table produced by the `ts_samples()` function, you can see that the tree sequence we simulated record *everyone*. It's very unlikely, unless we're extremely lucky, that we'll ever have a sequence of every single individual in a population that we study. To get a little closer to the scale of the genomic data that we'll be working with, we can restrict our simulation to only record a subset of individuals.

We can precisely define which individuals (from which populations, and at which times) should be recorded in a tree sequence using the *slendr* function `schedule_sampling()`. For instance, if we have a `model` with some *slendr* populations in variables `popX` `popY`, we can schedule the recording of 5 individuals from each at times 10000 (years ago) and 0 (present-day) by the following code:

```{r}
#| eval: false
pop_schedule <- schedule_sampling(model, times = c(10000, 0), list(popX, 5), list(popY), 5)
```

This function simply returns a data frame. As such, we can create multiple of such schedules (of arbitrary complexity and granularity), and then bind them together with a single line of code, like this:

```{r}
#| eval: false

# Note that the `times =` argument can be a vector of times...
ancient_times <- c(40000, 30000, 20000, 10000)
eur_samples <- schedule_sampling(model, times = ancient_times, list(eur, 1))
# ... but also just a single number
afr_samples <- schedule_sampling(model, times = 0, list(afr, 1), list(eur, 42))
nea_samples <- schedule_sampling(model, time = 60000, list(nea, 1))

# And that multiple such sampling schedules can be bound together like this:
samples <- rbind(eur_samples, afr_samples, nea_samples)
```

**Using the function `schedule_sampling` (and with the help of `rbind`), program the sampling of the following sample sets at given times, saving it to variable called `schedule`:**

| time  | population(s)   | \# individuals |
|-------|:----------------|----------------|
| 70000 | nea             | 1              |
| 40000 | nea             | 1              |
| 0     | chimp, afr, eur | 5              |

**Additionally, schedule the sampling of one `eur` individual at these times:**

```{r}
times <- seq(40000, 2000, by = -2000)
```

In total, you should schedule the recording of 38 individuals.

::: callout-note
#### Click to see the solution

```{r}
# Here we scheduled the sampling of two Neanderthals at 70kya and 40kya
nea_samples <- schedule_sampling(model, times = c(70000, 40000), list(nea, 1))
nea_samples # (this function produces a plain old data frame!)

# Here we schedule one Chimpanzee sample, 5 African samples, and 10 European samples
present_samples <- schedule_sampling(model, times = 0, list(chimp, 1), list(afr, 5), list(eur, 10))

# We also schedule the recording of one European sample between 50kya and 2kya,
# every 2000 years
times <- seq(40000, 2000, by = -2000)
emh_samples <- schedule_sampling(model, times, list(eur, 1))

# Because those functions produce nothing but a data frame, we can bind
# individual sampling schedules together
schedule <- rbind(nea_samples, present_samples, emh_samples)
schedule
```
:::

**Then, verify the correctness of your overall sampling `schedule` by visualizing it together with your `model` like this:**

::: aside
**Note:** As you've seen above, the visualization is often a bit wonky and convoluted with overlapping elements and it can be even worse with samples added, but try to experiment with arguments to `plot_model` described above to make the plot a bit more helpful for sanity checking.
:::

```{r}
#| eval: false
plot_model(model, samples = schedule)
```

::: callout-note
#### Click to see the solution

```{r}
plot_model(model, sizes = FALSE, samples = schedule)
```

```{r}
plot_model(model, sizes = FALSE, log = TRUE, samples = schedule)
```
:::

### Part 6: Simulating a defined set of individuals

**Use your combined sampling schedule stored in the `schedule` variable to run a new tree-sequence simulation from your model (again using the `msprime()` function), this time restricted to just those individuals scheduled for recording.** You can do this by providing the combined sampling schedule as the `samples =` argument of the function `msprime` you used above.

::: callout-note
#### Click to see the solution

```{r}
#| echo: false
model <- read_model(here::here("data/introgression"))
ts <- ts_read(file = here::here("data/introgression.trees"), model = model)
```

```{r}
#| eval: false
# The command below will likely take a few minutes to run, so feel free to go
# down from 100 Mb sequence_length to even 10Mb (it doesn't matter much)
# tstart <- Sys.time()
ts <-
  msprime(model, sequence_length = 100e6, recombination_rate = 1e-8, samples = schedule, random_seed = 1269258439) %>%
  ts_mutate(mutation_rate = 1e-8, random_seed = 1269258439)
# tend <- Sys.time()
# tend - tstart # Time difference of 2.141642 mins

# If you're bothered by ho long this takes, feel free to call these two lines
# to 100% reproduce my results without any expensive computation:
model <- read_model(here::here("data/introgression"))
ts <- ts_read(here::here(file = "data/introgression.trees"), model = model)

# We can save a tree sequence object using a slendr function `ts_write` (this
# can be useful if we want to save the results of a simulation for later use).
dir.create("data", showWarnings = FALSE)
ts_write(ts, "data/introgression.trees")
```
:::

**Inspect the tree-sequence object saved in the `ts` variable again, taking note of the (now much smaller!) number of individuals. You can also do a similar thing via the table produced by the `ts_samples()` function.**

::: callout-note
#### Click to see the solution

```{r}
# Inspect the (tskit/Python-based) summary of the new tree sequence
ts


# Get the table of all recorded samples in the tree sequence
ts_samples(ts)

# Compute the count of individuals in different time points
suppressPackageStartupMessages(library(dplyr))

ts_samples(ts) %>% group_by(pop, time == 0) %>% tally %>% select(pop, n)
```
:::

:::::: callout-tip
## Bonus exercises

### Bonus 1: Program your own model

Do you have a favourite model organism or you study another species? **Take some of the most important features of its demographic history and program them as a new *slendr* model.**\*
:::

<!-- End of Bonus exercises for Exercise 1 -->































# Exercise 2: Computing popgen statistics on tree sequences from *slendr*

In this exercise, you will build on top of the results from Exercise 1. Specifically, we will learn how to compute popgen statistics on *slendr*-simulated tree sequences using *slendr*'s interface to the *tskit* Python module.

First, create a new R script `exercise2.R` and paste in the following code. This is one of the possible solutions to the Exercise 1, and it's easier if we all use it to be on the same page from now on, starting from the same model and the same simulated tree sequence:

```{r}
#| collapse: true
library(slendr)
init_env()

chimp <- population("CHIMP", time = 7e6, N = 5000)
afr <- population("AFR", parent = chimp, time = 6e6, N = 15000)
eur <- population("EUR", parent = afr, time = 70e3, N = 3000)
nea <- population("NEA", parent = afr, time = 600e3, N = 1000, remove = 40e3)

gf <- gene_flow(from = nea, to = eur, rate = 0.03, start = 55000, end = 50000)

model <- compile_model(
  populations = list(chimp, nea, afr, eur),
  gene_flow = gf,
  generation_time = 30
)

ts <- ts_read(here::here("data/introgression.trees"), model = model)

cowplot::plot_grid(
  plot_model(model, proportions = TRUE),
  plot_model(model, proportions = TRUE, log = TRUE),
  nrow = 1
)
```

As a sanity check, let's make sure the tree sequence does contain a set of sample which matches our intended sampling schedule (particularly the time series of European individuals and the two Neanderthals):

```{r}
library(dplyr)

ts_samples(ts) %>% nrow
ts_samples(ts) %>% filter(pop == "EUR") %>% pull(time)
ts_samples(ts) %>% filter(pop == "NEA") %>% pull(time)
ts_samples(ts) %>% group_by(pop, time == 0) %>% tally %>% select(pop, n)
```

Everything looks good! Having made sure that the `ts` object contains the individuals we want, let's move to the exercise.

## Part 1: Computing nucleotide diversity

The model plotted above makes a fairly clear prediction on what would be the nucleotide diversity expected in the simulated populations. **Compute the nucleotide diversity in all populations using the *slendr* function [`ts_diversity()`](https://www.slendr.net/reference/ts_diversity.html#ref-examples). Do you get results you would expect from the model?**

**Hint:** Nearly every *slendr* statistic function interfacing with *tskit* accepts a `ts` tree-sequence object as its first argument, and with further arguments being either a vector of individual names representing a group of samples to compute a statistic on, or a (named) list of such vectors (each element of that list for a group of samples) -- these lists are intended to be equivalent to the `sample_sets =` argument of many *tskit* Python methods, except that they allow symbolic names of individuals, rather then integer indices of nodes in a tree sequence.

Although you can get all the above information by processing the table produced by the `ts_samples()` function, *slendr* provides a useful helper `ts_names()` which only returns the names of individuals.

When you call it directly, you get a plain vector of individual names:

```{r}
ts_names(ts)
```

This is not super helpful, unless we want to compute some statistic for *everyone* in the tree sequence, regardless of their population assignment. Perhaps a bit more useful is to call the function like this, because it will produce a result which can be immediately used as the `sample_sets =` argument mentioned in the **Hint** above:

```{r}
ts_names(ts, split = "pop")
```

As you can see, this gave us a normal R list, with each element containing a vector of individual names in a population. Note that we can use standard R list indexing to get subsets of individuals:

```{r}
names <- ts_names(ts, split = "pop")

names["NEA"]

names[c("EUR", "NEA")]
```

etc.

Many of the following exercises will use these kinds of tricks to instruct various *slendr* / *tskit* functions to compute statistics on subsets of all individuals sub-sampled in this way.

**After you computed the nucleotide diversity per-population, compute it for each individual separately using the same function `ts_diversity()`, which gives you the heterozygosity for each individual.**

**Hint:** You can do this by giving a vector of names as `sample_sets =` (so not an R list of vectors). Feel free to take a look at the solution if you find this distinction confusing.

::: callout-note
### Click to see the solution

**Population-based nucleotide diversity:**

```{r}
# Let's first get a named list of individuals in each group we want to be
# working with (slendr tree-sequence statistic functions generally operate
# with this kind of structure)
sample_sets <- ts_names(ts, split = "pop")
sample_sets

# We can use such `sample_sets` object to compute nucleotide diversity (pi)\
# in each population, in a bit of a similar manner to how we would do it
# with the standard tskit in Python
pi_pop <- ts_diversity(ts, sample_sets = sample_sets)
arrange(pi_pop, diversity)
```

**Per-individual heterozygosity:**

We can do this by passing the vector of individual names directory as the `sample_sets =` argument, rather than in a list of groups as we did above.

```{r}
# For convenience, we first get a table of all individuals (which of course
# contains also their names) and in the next step, we'll just add their
# heterozygosities as a new column.
pi_df <- ts_samples(ts)
pi_df$name

pi_df$diversity <- ts_diversity(ts, sample_sets = pi_df$name)$diversity
pi_df

# Let's plot the results using the ggplot2 package
# (because a picture is worth a thousand numbers!)
library(ggplot2)

ggplot(pi_df, aes(pop, diversity, color = pop, group = pop)) +
  geom_boxplot(outlier.shape = NA) +
  geom_jitter() +
  theme_bw()
```
:::

## Part 2: Computing pairwise divergence

**Use the function [`ts_divergence()`](https://www.slendr.net/reference/ts_divergence.html#ref-examples) to compute genetic divergence between all pairs of populations.** Do you get results compatible with our demographic model?

**Hint:** Again, you can use the same concept of `sample_sets =` we discussed in the previous part.

::: callout-note
### Click to see the solution

```{r}
sample_sets <- ts_names(ts, split = "pop")

div_df <- ts_divergence(ts, sample_sets)
arrange(div_df, divergence)
```
:::

## Part 3: Detecting Neanderthal admixture in Europeans

Let's now pretend its about 2008 and we've sequenced the first Neanderthal genome (and also have the genomes of a couple of people from Africa and Europe). We want to answer the most burning question of all evolutionary anthropology: *"Do some people living today carry Neanderthal ancestry?"*

Earlier you've learned about $f$-statistics of various kinds. You have also heard that an $f_4$ statistic (or its equivalent $D$ statistic) can be used as a test of "treeness". Simply speaking, for some "quartet" of individuals or population samples, they can be used as a hypothesis test of whether the history of those samples is compatible with there **not** having been an introgression.

**Compute the** $f_4$ test of Neanderthal introgression in EUR individuals using the *slendr* function `ts_f4()`. When you're running it, you will have to provide individuals to compute the statistic on using a slightly different format. Take a look at the help page available as `?ts_f4` for more information. **When you're computing the values, make sure to also set `mode = "branch"` (we will get to why a bit later).**

**Hint:** If you haven't learned this in your $f$-statistics lecture, you want to compute (and compare) the values of these two statistics using the *slendr* function `ts_f4()`:

-   $f_4$(\<some African\>, \<another African\>; \<Neanderthal\>, \<Chimp\>)

-   $f_4$(\<some African\>, \<a test European\>; \<Neanderthal\>, \<Chimp\>)

Roughly speaking, we can understand this computation in terms of comparing the counts of so-called BABA and ABBA allele patterns between the quarted of samples specified in the statistics:

$$
f_4(AFR, X; NEA, CHIMP) = \frac{\#BABA - \#ABBA}{\#SNPs}
$$

The first is not expected to give values "too different" from 0 because we don't expect two African individuals to differ "significantly" in terms of how much alleles they share with a Neanderthal. The other should -- if there was a Neanderthal introgression into Europeans some time in their history -- be "significantly negative".

**Is the second of those two statistics "much more negative" than the first, as expected assuming introgression from Neanderthals into Europeans?**

**Why am I putting "significantly" and "much more negative" in quotes? What are we missing here for this being a true hypothesis test as you might be accustomed to from computing** $f$-statistics using a tool such as ADMIXTOOLS? (We will get to this again in the following part of this exercise.)

::: callout-note
### Click to see the solution

```{r}
# Compute the difference in the amount of allele sharing between two African
# individuals and a Neanderthal
f4_null <- ts_f4(ts, W = "AFR_1", X = "AFR_2", Y = "NEA_1", Z = "CHIMP_1", mode = "branch")
f4_null

# Compute the difference in the amount of allele sharing between an African
# individual vs European individual and a Neanderthal
f4_alt <- ts_f4(ts, W = "AFR_1", X = "EUR_1", Y = "NEA_1", Z = "CHIMP_1", mode = "branch")
f4_alt

# We can see that the second test resulted in an f4 value about ~20 times more
# negative than the first test, indicating that a European in our test carries
# "significantly more" Neanderthal alleles compared to the baseline expectation
# of no introgression established by the comparison to an African ...
f4_alt$f4 / f4_null$f4

# ... although this is not a real test of significance (we have no Z-score or
# standard error which would give us something like a p-value for the hypothesis
# test, as we get by jackknife procedure in ADMIXTOOLS)
```
:::

## Part 5: Detecting Neanderthal admixture in Europeans v2.0

The fact that we don't get something equivalent to a p-value in these kinds of simulations is generally not a problem, because we're often interested in establishing a trend of a statistic under various conditions, and understanding when and how it behaves in a certain way. If statistical noise is a problem, we can easily work around it by computing a statistic on multiple simulation replicates or even increasing the sample sizes. I used this approach quite successfully on a related problem in [this paper](https://www.pnas.org/doi/10.1073/pnas.1814338116#fig02).

On top of that, p-value of something like an $f$-statistic (whether it's significantly different from zero) is also strongly affected by quality of the data, sequencing errors, coverage, etc. (which can certainly be done using simulations!). However, these are an orthogonal issue which has little to do with the underlying evolutionary model in question anyway -- and that's what we're after in our exercises.

In short, how much is "significantly different from zero compared to some baseline expectation" can be easily drowned in noise in a simple single-individual comparisons as we did above. Let's increase the sample size a bit to see if a statistical pattern becomes more apparent.

**Compute the first** $f_4$ statistic of the baseline expectation between a pair of Africans and the second $f_4$ statistic comparing an African and a European, but this time on *all recorded Africans* and *all recorded Europeans*, respectively. Plot the *distributions* of those two sets of statistics. This should remove lots of the uncertainty and make a statistical trend stand out much more clearly.

**Hint:** Whenever you need to compute something for many things in sequence, looping is very useful. One way to do compute, say, an $f_4$ statistic over many individuals is use this kind of pattern using R's looping function `lapply()`:

```{r}
#| eval: false

# Loop over vector of individual names and apply a given ts_f4() expression on each
list_f4 <- lapply(
  c("ind_1", "ind_2", ...),
  function(x) ts_f4(ts, W = "AFR_1", X = x, Y = "NEA_1", Z = "CHIMP_1", mode = "branch")
)

# The above gives us a list of data frames, so we need to bind them all into a
# single table for easier interpretation and visualization
df_f4 <- do.call(rbind, list_f4)
```

::: callout-note
### Click to see the solution

```{r}
# Let's compute the f4 statistic for all Africans and Europeans to see the
# f4 introgression patterns more clearly
f4_afr <- lapply(sample_sets$AFR, function(x) ts_f4(ts, W = "AFR_1", X = x, Y = "NEA_1", Z = "CHIMP_1", mode = "branch")) %>% do.call(rbind, .)
f4_afr
f4_eur <- lapply(sample_sets$EUR, function(x) ts_f4(ts, W = "AFR_1", X = x, Y = "NEA_1", Z = "CHIMP_1", mode = "branch")) %>% do.call(rbind, .)
f4_eur

# Let's add population columns to each of the two results, and bind them together
# for plotting
f4_afr$pop <- "AFR"
f4_eur$pop <- "EUR"

# Bind both tables together
f4_results <- rbind(f4_afr, f4_eur)

# Visualize the results
f4_results %>%
  ggplot(aes(pop, f4, color = pop)) +
  geom_boxplot() +
  geom_jitter() +
  geom_hline(yintercept = 0, linetype = 2) +
  ggtitle("f4(AFR, EUR; NEA, CHIMP)") +
  theme_bw()

# Why the difference between the "branch" and "site" modes?
# See this tutorial (and particularly directly the linked section):
# https://tskit.dev/tutorials/no_mutations.html#genealogy-based-measures-are-less-noisy

```
:::

::: callout-tip
## Bonus exercises

### Bonus 1: Outgroup $f_3$ statistic

**Use the function `ts_f3()` to compute the outgroup** $f_3$ statistic between pairs of African-European, African-Neanderthal, and European-Neanderthal and a Chimpanzee outgroup.

**Hint:** The $f_3$ statistic is traditionally expressed as $f_3(A, B; C)$, where C represents the outgroup. Unfortunately, in *tskit* the outgroup is named A, with B and C being the pair of samples from which we trace the length of branches towards the outgroup, so the statistic is interpreted as $f_3(B, C; A)$.

**How do the outgroup f3 results compare to your expectation based on simple population relationships (and to the divergence computation above)?**

**Do you see any impact of introgression on the \$f_3 value when a Neanderthal is included in the computation?**

::: callout-note
### Click to see the solution

```{r}
# f3(A, B; C) = E[ (A - C) * (B - C) ]
# This means that in tskit, C is the outgroup (different from ADMIXTOOLS!)

# We can compute f3 for individuals...
ts_f3(ts, B = "AFR_1", C = "EUR_1", A = "CHIMP_1")

# ... but also whole populations (or population samples)
ts_f3(ts, B = sample_sets["AFR"], C = sample_sets["EUR"], A = "CHIMP_1")

ts_f3(ts, B = sample_sets["AFR"], C = sample_sets["NEA"], A = "CHIMP_1")

ts_f3(ts, B = sample_sets["EUR"], C = sample_sets["NEA"], A = "CHIMP_1")
```
:::

### Bonus 2: Outgroup $f_3$ statistic as a linear combination of $f_2$ statistics

You might have learned that any complex $f$-statistic can be expressed as a linear combination of multiple $f_2$ statistics (which represent simple branch length separating two lineages). **Verify that this is the case by looking up equation *(20b)* in [this amazing paper](https://academic.oup.com/genetics/article/202/4/1485/5930214) and compute an** $f_3$ statistic for any arbitrary trio of individuals of your choosing using this linear combination of $f_2$ statistics.

::: callout-note
### Click to see the solution

```{r}
# standard f3
ts_f3(ts, B = "AFR_1", C = "AFR_2", A = "CHIMP_1")

# a "homemade" f3 statistic as a linear combination of f2 statistics
# f3(A, B; C) = f2(A, C) + f2(B, C) - f2(A, B) / 2
homemade_f3 <- (
  ts_f2(ts, A = "AFR_1", B = "CHIMP_1")$f2 +
  ts_f2(ts, A = "AFR_2", B = "CHIMP_1")$f2 -
  ts_f2(ts, A = "AFR_1", B = "AFR_2")$f2
) / 2
homemade_f3
```
:::

### Bonus 3: Trajectory of Neanderthal ancestry in Europe over time

There used to be a lot of controversy about the question of whether or not did Neanderthal ancestry proportion in Europeans decline or not over the past 40 thousand years (see figure 1 in [this paper](https://www.pnas.org/doi/full/10.1073/pnas.1814338116) figure 2 in [this paper](https://www.nature.com/articles/nature17993)).

Your simulated tree sequence contains a time-series of European individuals over time. Use the *slendr* function `ts_f4ratio()` to compute (and then plot) the proportion (commonly designated as `alpha`) of Neanderthal ancestry in Europe over time. Use $f_4$-ratio statistic of the following form:

```{r}
#| eval: false
ts_f4ratio(ts, X = <vector of ind. names>, A = "NEA_1", B = "NEA_2", C = "AFR_1", O = "CHIMP_1")
```

::: callout-note
### Click to see the solution

```{r}
# Extract table with names and times of sampled Europeans (ancient and present day)
eur_inds <- ts_samples(ts) %>% filter(pop == "EUR")
eur_inds

# Compute f4-ration statistic (this will take ~30s) -- note that we can provide
# a vector of names for the X sample set to the `ts_f4ratio()` function
nea_ancestry <- ts_f4ratio(ts, X = eur_inds$name, A = "NEA_1", B = "NEA_2", C = "AFR_1", O = "CHIMP_1")

# Add the age of each sample to the table of proportions
nea_ancestry$time <- eur_inds$time
nea_ancestry

nea_ancestry %>%
  ggplot(aes(time, alpha)) +
  geom_point() +
  geom_smooth(method = "lm", linetype = 2, color = "red", linewidth = 0.5) +
  xlim(40000, 0) +
  coord_cartesian(ylim = c(0, 0.1)) +
  labs(x = "time [years ago]", y = "Neanderthal ancestry proportion") +
  theme_bw() +
  ggtitle("Neanderthal ancestry proportion in Europeans over time")

# For good measure, let's test the significance of the decline using a linear model
summary(lm(alpha ~ time, data = nea_ancestry))
```
:::

### Bonus 4 -- how many unique f4 quartets are there?

In your lecture about $f$-statistics, you've probably learned about various symmetries in $f_4$ (but also other $f$-statistics) depending on the arrangement of the "quartet". As a trivial example, an $f_3(A; B, C)$ and $f_3(A; C, B)$ will give you exactly the same value, and the same thing applies even to more complex $f$-statistics like $f_4$.

**Use simulations to compute how manu unique** $f_4$ values involving a single quartet are there.

**Hint:** Draw some trees to figure out why could that be true. Also, when computing `ts_f4()`, set `mode = "branch"` to avoid the effect of statistical noise due to mutations.

::: callout-note
### Click to see the solution

```{r}
# # install a combinatorics R package
# install.packages("combinat")

library(combinat)

# These are the four samples we can create quartet combinations from
quartet <- c("AFR_1", "EUR_1", "NEA_1", "CHIMP_1")
quartets <- permn(quartet)
quartets

# How many permutations there are in total?
#   4! = 4 * 3 * 2 * 1 = 24
factorial(4)

# We should therefore have 24 different quartet combinations of samples
length(quartets)

# Loop across all quartets, computing the corresponding f4 statistic (we want
# to do this using branch lengths, not mutations, as the mutation-based computation
# would involve statistical noise)
all_f4s <- lapply(quartets, function(q) ts_f4(ts, q[1], q[2], q[3], q[4], mode = "branch"))

# Bind the list of f4 results into a single data frame and inspect the results
all_f4s <- bind_rows(all_f4s) %>% arrange(abs(f4))
print(all_f4s, n = Inf)

# Narrow down the results to only unique f4 values
distinct(all_f4s, f4, .keep_all = TRUE)
distinct(all_f4s, abs(f4), .keep_all = TRUE)
```
:::
::::::
<!-- End of Bonus exercises for Exercise 2 -->































# Exercise 3: Simulation-based inference of $N_e$ from AFS

What we did so far is learning how *slendr* models provide an easy way to encode
demographic models in R and simulate (even very large!) tree sequences from them.
This allows us to very quickly verify our intuition about some popgen problem
(things like _"Hmmm, I wonder what would an $f_4$ statistic look like if my model
includes this particular gene-flow event?_), in just a few lines of R. We have
been able to even answer some questions like this directly in a meeting, pretty
much on the spot! This makes _slendr_ a very powerful "popgen calculator".

Now let's take things one step forward. Imagine you gathered some empirical
data, like an allele frequency spectrum (AFS). That data was, in the real world,
produced by some (hidden) biological process (demographic history) that we
generally don't know anything about a priori For instance, the population we study
had some $N_e$, which we don't know -- the only thing we have is the observed AFS.

Simulations can be a great tool to estimate the most likely value of an unknown
parameter. Staying with this $N_e$ and AFS example, can simulate a large number
of AFS vectors (each resulting from a different assumed $N_e$ value) and then pick
just those $N_e$ values (or just one $N_e$ value) which produced a simulated AFS
closest to the observed AFS. **This is exactly what you'll be doing just now 
in Exercise 3.**

## Part 1: A self-contained *slendr* function of $N_e \rightarrow \textrm{AFS}$

**In a new script `exercise3.R` write a custom R function called `simulate_afs()`,
which will take `Ne` as its only parameter. Use this function to compute AFS
vectors for a couple of `Ne` values of your choosing, but staying between
`Ne = 1000` and `Ne = 30000` Plot those AFS vectors and observe how (and why?)
do they differ based on `Ne` parameter you used in each respective simulation.**

**Hint:** The function should create a one-population *forward-time* model
(our population starting at `time = 1`, with the model `simulation_length` 100000
and `generation_time` 1), simulate 10Mb tree sequence (recombination and mutation
rates of 1e-8), compute AFS for 10 samples and return it the AFS vector as its result.

**Hint:**

If you've never programmed before, the concept of a "custom function" might
be very alien to you. If you need help, feel free to start building your
`exercise3.R` solution based on this "template" (just fill in missing relevant
bits of _slendr_ code that you should be already familiar with):

```{r}
#| eval: false
library(slendr)
init_env()

simulate_afs <- function(Ne) {
  # In here you should write code which will compile a single-population
  # demographic model based on the parameters specified above. It should
  # then simulate 10Mb of tree sequence using `msprime()`, compute an AFS
  # vector using the function `ts_afs()` for any subset of 10 individuals
  # in the tree sequence, and finally return that vector.

  return(result) # `result` is a variable with your 10-sample AFS, return it
}

afs_1 <- simulate_afs(Ne = 1000) # simulate AFS from a Ne = 1000 model...
plot(afs_1, type ="o")           # ... and plot it
```

**Note:** Remember that you should drop the first element of the AFS vector produced by `ts_afs()` (for instance with something like `result[-1]` if `result` contains the output of `ts_afs()`) technical reasons related to *tskit*. You don't have to worry about that here, but you can read [this](https://tskit.dev/tutorials/analysing_tree_sequences.html#sec-tutorial-afs-zeroth-entry) for more detail.

When used in R, your function should work like this:

```{r}
#| echo: false
simulate_afs <- function(Ne) {
  n <- 20 # 1 is for the fixed sites included by tskit
  theta <- 4 * 1e-8 * Ne * 100e6
  round(theta * 1/1:n)
}
```

```{r}
simulate_afs(Ne = 1000)
```



::: callout-note
#### Click to see the solution
```{r}
# An R function can be understood as a block of a computer program which executes
# a block of code inside the {...} brackets given a certain value of a parameter
# (here 'Ne' just after the word 'function')
simulate_afs <- function(Ne) {
  # create a slendr model with a single population of size Ne = N
  pop <- population("pop", N = Ne, time = 1)
  model <- compile_model(pop, generation_time = 1, simulation_length = 100000)

  # simulate a tree sequence
  ts <-
    msprime(model, sequence_length = 10e6, recombination_rate = 1e-8) %>%
    ts_mutate(mutation_rate = 1e-8)

  # get a random sample of names of 10 individuals
  samples <- ts_names(ts) %>% sample(10)

  # compute the AFS vector (dropping the 0-th element added by tskit)
  afs <- ts_afs(ts, sample_sets = list(samples))[-1]

  afs
}

# Let's use our custom function to simulate AFS vector for Ne = 1k, 10k, and 30k
afs_1k <- simulate_afs(1000)
afs_10k <- simulate_afs(10000)
afs_30k <- simulate_afs(30000)

# Plot the three simulated AFS using base R plotting functionality
plot(afs_30k, type = "o", main = "AFS, Ne = 30000", col = "cyan",)
lines(afs_10k, type = "o", main = "AFS, Ne = 10000", col = "purple")
lines(afs_1k, type = "o", main = "AFS, Ne = 1000", col = "blue")
legend("topright", legend = c("Ne = 1k", "Ne = 10k", "Ne = 30k"),
       fill = c("blue", "purple", "cyan"))
```
:::




## Part 2: Estimating unknown $N_e$ from empirical AFS

```{r}
#| eval: false
#| echo: false
set.seed(42)
TRUE_NE <- 6543

pop <- population("pop", N = TRUE_NE, time = 100000)
model <- compile_model(pop, generation_time = 1, direction = "backward")

ts <-
  msprime(model, sequence_length = 10e6, recombination_rate = 1e-8, random_seed = 42) %>%
  ts_mutate(mutation_rate = 1e-8, random_seed = 42)

samples <- ts_names(ts) %>% sample(10)

afs_observed <- ts_afs(ts, list(samples))
```

Imagine you sequenced 10 samples from a population and computed the following
AFS vector (which contains, sequentially, the number of singletons, doubletons, etc.):

<!-- dput(as.vector(observed_afs)) -->

```{r}
afs_observed <- c(2520, 1449, 855, 622, 530, 446, 365, 334, 349, 244,
                  264, 218,  133, 173, 159, 142, 167, 129, 125, 143)
```

You know (maybe from some fossil evidence) that the population probably had
a constant $N_e$ somewhere between 1000 and 30000 for the past 100,000 generations,
and had mutation and recombination rates of 1e-8 (i.e., parameters already
implemented by your `simulate_afs()` function).

**Use _slendr_ simulations to guess the true (and hidden!) $N_e$ given the observed
AFS by running simulations for a range of $N_e$ values and comparing each run to
the `afs_observed` vector above.**

**Hints:**

Depending on your level of comfort with R (and programming in general), you can
choose one of the following approaches:

- **Option 1** [easy]: Plot AFS vectors for various $N_e$ values, then eyeball
which looks closest to the observed AFS based on the figures alone.

- **Option 2** [hard]: Simulate AFS vectors in steps of possible `Ne` (maybe
`lapply()`?), and find the $N_e$ which gives the closest AFS to the observed AFS based on [Mean squared error](https://en.wikipedia.org/wiki/Mean_squared_error).



::: callout-note
#### Click to see the solution to "Option 1"
```{r}
# This is our starting observed AFS which we want to compare simulated AFS vectors to
afs_observed <- c(2520, 1449, 855, 622, 530, 446, 365, 334, 349, 244,
                  264, 218,  133, 173, 159, 142, 167, 129, 125, 143)

# We know that the Ne is between 1000 and 30000, so let's simulate
# a bunch of AFS vectors for different Ne values
afs_Ne1k <- simulate_afs(Ne = 1000)
afs_Ne5k <- simulate_afs(Ne = 5000)
afs_Ne6k <- simulate_afs(Ne = 6000)
afs_Ne10k <- simulate_afs(Ne = 10000)
afs_Ne20k <- simulate_afs(Ne = 20000)
afs_Ne30k <- simulate_afs(Ne = 30000)

# Plot all simulated AFS vectors, highlighting the observed AFS in black
plot(afs_observed, type = "b", col = "black", lwd = 3,
     xlab = "allele count bin", ylab = "count", ylim = c(0, 13000))
lines(afs_Ne1k, lwd = 2, col = "blue")
lines(afs_Ne5k, lwd = 2, col = "green")
lines(afs_Ne6k, lwd = 2, col = "pink")
lines(afs_Ne10k, lwd = 2, col = "purple")
lines(afs_Ne20k, lwd = 2, col = "orange")
lines(afs_Ne30k, lwd = 2, col = "cyan")
legend("topright",
       legend = c("observed AFS", "Ne = 1000", "Ne = 5000",
                  "Ne = 6000", "Ne = 10000", "Ne = 20000", "Ne = 30000"),
       fill = c("black", "blue", "green", "pink", "purple", "orange", "cyan"))


# !!!!! SPOILER ALERT BEFORE REVEALING THE CORRECT ANSWER !!!!!
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
# true Ne was 6543!
```
:::



::: callout-note
#### Click to see the solution to "Option 1"

```{r}
# This is our starting observed AFS which we want to compare simulated AFS vectors to
afs_observed <- c(2520, 1449, 855, 622, 530, 446, 365, 334, 349, 244,
                  264, 218,  133, 173, 159, 142, 167, 129, 125, 143)

# Generate regularly spaced values of potential Ne values (our parameter grid)
Ne_grid <- seq(from = 1000, to = 30000, by = 500)
Ne_grid

library(parallel)

# Compute AFS (in parallel, to make things faster) across the entire grid of possible Ne values
afs_grid <- mclapply(Ne_grid, simulate_afs, mc.cores = detectCores())
names(afs_grid) <- Ne_grid

# Show the first five simulated AFS vectors, for brevity
afs_grid[1:5]



# Plot the observed AFS...
plot(afs_observed, type = "b", col = "black", lwd = 3, xlab = "allele count bin", ylab = "count")
# ... and overlay the simulated AFS vectors on top of it
for (i in seq_along(Ne_grid)) {
  lines(afs_grid[[i]], lwd = 0.5)
}
legend("topright", legend = c("observed AFS", "simulated AFS"), fill = c("black", "gray"))




# Compute mean-squared error of the AFS produced by each Ne value across the grid
errors <- sapply(afs_grid, function(sim_afs) {
  sum((sim_afs - afs_observed)^2) / length(sim_afs)
})

plot(Ne_grid, errors, ylab = "error")
abline(v = Ne_grid[which.min(errors)], col = "red")
legend("topright", legend = paste("minimum error Ne =", Ne_grid[which.min(errors)]), fill = "red")




# Plot the AFS again, but this time highlight the most likely spectrum
# (i.e. the one which gave the lowest RMSE value)
plot(afs_observed, type = "b", col = "black", lwd = 3, xlab = "allele count bin", ylab = "count")
for (i in seq_along(Ne_grid)) {
  color <- if (i == which.min(errors)) "red" else "gray"
  width <- if (i == which.min(errors)) 2 else 0.75
  lines(afs_grid[[i]], lwd = width, col = color)
}
legend("topright", legend = c("observed AFS", paste("best fitting Ne =", Ne_grid[which.min(errors)])),
       fill = c("black", "red"))


# !!!!! SPOILER ALERT BEFORE REVEALING THE CORRECT ANSWER !!!!!
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
# true Ne was 6543!
```
:::






























# Exercise 4: Simulating dynamics of positive selection































# Exercise 5: Playing around with PCA patterns
